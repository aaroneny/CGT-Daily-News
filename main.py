import feedparser
import datetime
import pytz
from deep_translator import GoogleTranslator
from time import mktime
import re

# --- 1. é«˜ç²¾ RSS æºé…ç½® ---
# æˆ‘ä»¬æ„å»ºäº† 3 ä¸ªé’ˆå¯¹æ€§çš„æœç´¢ç»„åˆï¼Œå…¨éƒ¨é™å®šåœ¨ 24 å°æ—¶å†… (when:1d)
RSS_URLS = [
    # [é€šé“ A] In vivo CAR-T ä¸ ä¸‹ä¸€ä»£ç»†èƒæ²»ç–— (æœ€æ ¸å¿ƒ)
    # æœç´¢é€»è¾‘ï¼šå¿…é¡»åŒ…å« "In vivo" ä¸”å¿…é¡»åŒ…å« (CAR-T æˆ– åŸºå› ç¼–è¾‘ æˆ– LNP)ï¼Œé”å®šä¼ä¸šé€šç¨¿
    "https://news.google.com/rss/search?q=(site:businesswire.com+OR+site:prnewswire.com+OR+site:globenewswire.com)+AND+%22In+vivo%22+AND+(%22CAR-T%22+OR+%22Gene+Editing%22+OR+%22LNP%22+OR+%22Vector%22)+when:1d&hl=en-US&gl=US&ceid=US:en",

    # [é€šé“ B] å¸¸è§„ CAR-T ä¼ä¸šé‡å¤§è¿›å±• (æ’é™¤ç§‘æ™®æ–‡ç« )
    # æœç´¢é€»è¾‘ï¼šCAR-T + (IND æˆ– ä¸´åºŠ æˆ– FDA æˆ– èèµ„)ï¼Œæ’é™¤å¸‚åœºæŠ¥å‘Š
    "https://news.google.com/rss/search?q=(site:businesswire.com+OR+site:prnewswire.com+OR+site:globenewswire.com)+AND+%22CAR-T%22+AND+(IND+OR+FDA+OR+Clinical+OR+Pipeline+OR+Dosed)+when:1d&hl=en-US&gl=US&ceid=US:en",

    # [é€šé“ C] FDA ç›‘ç®¡ä¸å®¡æ‰¹ç‰¹åˆ«é€šé“ (åŒ…å« FDA å®˜ç½‘)
    # æœç´¢é€»è¾‘ï¼šFDA + (ç»†èƒæ²»ç–— æˆ– åŸºå› æ²»ç–—) + (æŒ‡å— æˆ– æ‰¹å‡† æˆ– æš‚åœ)
    "https://news.google.com/rss/search?q=(site:fda.gov+OR+site:businesswire.com+OR+site:prnewswire.com)+AND+FDA+AND+(%22Cell+Therapy%22+OR+%22Gene+Therapy%22)+AND+(Guidance+OR+Approval+OR+IND+OR+Hold)+when:1d&hl=en-US&gl=US&ceid=US:en"
]

# --- 2. å…³é”®è¯ç™½åå• (å‘½ä¸€å³å¯) ---
KEYWORDS = [
    # æ ¸å¿ƒæŠ€æœ¯
    "In vivo", "In-vivo", "CAR-T", "CAR T", "Chimeric Antigen Receptor",
    "T-cell", "NK Cell", "TCR-T", "LNP", "Viral Vector", "AAV",
    
    # ç›‘ç®¡ä¸å®¡æ‰¹ (FDA)
    "FDA", "CBER", "IND", "BLA", "Fast Track", "Orphan Drug", "RMAT",
    "Approval", "Approved", "Cleared", "Green light", "Guidance", "Guideline",
    "Clinical Hold", "Complete Response Letter", "CRL",
    
    # ä¸´åºŠå…³é”®èŠ‚ç‚¹
    "Phase 1", "Phase I", "First Patient Dosed", "Trial Start", "Top-line data"
]

# --- 3. å™ªéŸ³é»‘åå• ---
EXCLUDE_WORDS = [
    "Market size", "Market report", "Growth analysis", "CAGR", "Forecast", # å¸‚åœºæŠ¥å‘Š
    "Lawsuit", "Class action", "Investigation", # å¾‹å¸ˆäº‹åŠ¡æ‰€é€šç¨¿
    "Dividend", "Quarterly results", "Financial results", # çº¯è´¢æŠ¥
    "Skincare", "Cosmetic", "Veterinary" # æ’é™¤æ— å…³é¢†åŸŸ
]

def is_recent(published_parsed):
    """ä¸¥æ ¼çš„24å°æ—¶ç†”æ–­æ£€æŸ¥"""
    if not published_parsed: return False
    news_time = datetime.datetime.fromtimestamp(mktime(published_parsed)).replace(tzinfo=pytz.utc)
    current_time = datetime.datetime.now(pytz.utc)
    return (current_time - news_time).total_seconds() <= 86400

def highlight_title(title):
    """è§†è§‰å¢å¼ºï¼šä¸ºé‡ç‚¹è¯æ·»åŠ  Emoji æˆ– åŠ ç²—"""
    # æ ‡è®° In vivo
    if re.search(r"In\s*vivo", title, re.IGNORECASE):
        title = "ğŸ”¥ " + title
    # æ ‡è®° FDA/Approval
    if re.search(r"FDA|Approval|Approved|IND", title, re.IGNORECASE):
        title = "ğŸ›ï¸ " + title
    return title

def fetch_news():
    news_items = []
    seen_links = set()
    translator = GoogleTranslator(source='auto', target='zh-CN')

    print("æ­£åœ¨æ ¹æ®ç‰¹å®šç­–ç•¥æ‰«æ FDA ä¸ In vivo CAR-T èµ„è®¯...")

    for url in RSS_URLS:
        feed = feedparser.parse(url)
        for entry in feed.entries:
            title = entry.title
            link = entry.link
            
            # 1. æ—¶é—´æ¸…æ´—
            if not is_recent(entry.published_parsed): continue
            # 2. å»é‡
            if link in seen_links: continue
            seen_links.add(link)

            # 3. å…³é”®è¯åŒé‡æ ¡éªŒ
            if any(k.lower() in title.lower() for k in KEYWORDS) and \
               not any(e.lower() in title.lower() for e in EXCLUDE_WORDS):
                
                # æ¸…ç†å¹¶ç¿»è¯‘
                clean_title_en = title.rsplit(' - ', 1)[0]
                try:
                    title_zh = translator.translate(clean_title_en)
                except:
                    title_zh = "ç¿»è¯‘æš‚ä¸å¯ç”¨"

                # æ ¼å¼åŒ–æ—¶é—´
                news_dt = datetime.datetime.fromtimestamp(mktime(entry.published_parsed)).replace(tzinfo=pytz.utc)
                beijing_dt = news_dt.astimezone(pytz.timezone('Asia/Shanghai'))
                
                news_items.append({
                    "title_zh": highlight_title(title_zh), # ä¸­æ–‡æ ‡é¢˜åŠ é«˜äº®
                    "title_en": clean_title_en,
                    "link": link,
                    "date_str": beijing_dt.strftime('%m-%d %H:%M'),
                    "timestamp": news_dt.timestamp()
                })
    
    news_items.sort(key=lambda x: x["timestamp"], reverse=True)
    return news_items

def update_readme(news_items):
    beijing_tz = pytz.timezone('Asia/Shanghai')
    today_str = datetime.datetime.now(beijing_tz).strftime("%Y-%m-%d")
    
    with open("README.md", "r", encoding="utf-8") as f:
        content = f.read()

    header_marker = "## ğŸ§¬ æ¯æ—¥ç²¾é€‰ï¼šIn vivo CAR-T & FDA"
    new_header = f"{header_marker}\n> æ›´æ–°æ—¥æœŸ: {today_str} (ç­›é€‰æ ‡å‡†: In vivo / CAR-T / FDA Approval / IND)\n\n"
    
    # æ„å»ºæ–°é—»åˆ—è¡¨è¡¨æ ¼æˆ–åˆ—è¡¨
    news_list = ""
    for item in news_items:
        news_list += f"- `[{item['date_str']}]` **{item['title_zh']}**\n  <br><small>ğŸ‡¬ğŸ‡§ *{item['title_en']}* [ğŸ”—åŸæ–‡]({item['link']})</small>\n"
    
    if not news_items:
        news_list += "- è¿‡å»24å°æ—¶å†…æœªç›‘æµ‹åˆ°ç¬¦åˆã€ŒIn vivo CAR-Tã€æˆ–ã€ŒFDAé‡å¤§å®¡æ‰¹ã€çš„ä¸€æ‰‹é€šç¨¿ã€‚\n"

    # é€»è¾‘ï¼šä¿ç•™ README å¤´éƒ¨ä»‹ç»ï¼Œæ›¿æ¢æ–°é—»åŒºåŸŸ
    if header_marker in content:
        final_content = content.split(header_marker)[0] + new_header + news_list
    else:
        final_content = content + "\n\n" + new_header + news_list

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(final_content)

if __name__ == "__main__":
    items = fetch_news()
    update_readme(items)

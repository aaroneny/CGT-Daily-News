import feedparser
import datetime
import pytz
from deep_translator import GoogleTranslator

# 1. é…ç½®æ•°æ®æº
RSS_URLS = [
    "https://news.google.com/rss/search?q=Cell+Gene+Therapy+FDA+IND&hl=en-US&gl=US&ceid=US:en",
    "https://news.google.com/rss/search?q=CAR-T+approval+pipeline&hl=en-US&gl=US&ceid=US:en",
    "https://news.google.com/rss/search?q=biotech+series+funding+cell+therapy&hl=en-US&gl=US&ceid=US:en"
]

# 2. å…³é”®è¯è¿‡æ»¤
KEYWORDS = ["FDA", "IND", "approval", "cleared", "clinical trial", "submission", "green light", "Series A", "Series B"]
EXCLUDE_WORDS = ["market report", "stocks", "forecast", "size", "share"] 

def fetch_news():
    news_items = []
    seen_links = set()
    
    # åˆå§‹åŒ–ç¿»è¯‘å™¨ï¼šè‡ªåŠ¨æ£€æµ‹æºè¯­è¨€ -> ç¿»è¯‘æˆç®€ä½“ä¸­æ–‡
    translator = GoogleTranslator(source='auto', target='zh-CN')

    print("æ­£åœ¨è·å–æ–°é—»å¹¶ç¿»è¯‘ï¼Œè¯·ç¨å€™...") # æ–¹ä¾¿åœ¨ Action æ—¥å¿—ä¸­æŸ¥çœ‹è¿›åº¦

    for url in RSS_URLS:
        feed = feedparser.parse(url)
        for entry in feed.entries:
            title = entry.title
            link = entry.link
            pub_date = entry.published
            
            if link in seen_links:
                continue
            seen_links.add(link)

            # è¿‡æ»¤é€»è¾‘
            if any(k.lower() in title.lower() for k in KEYWORDS) and \
               not any(e.lower() in title.lower() for e in EXCLUDE_WORDS):
                
                # --- æ–°å¢ï¼šæ¸…ç†æ ‡é¢˜å¹¶ç¿»è¯‘ ---
                # å»æ‰ Google News å¸¸è§çš„å°¾å·´ï¼Œå¦‚ " - BioSpace"
                clean_title_en = title.rsplit(' - ', 1)[0]
                
                try:
                    # æ‰§è¡Œç¿»è¯‘
                    title_zh = translator.translate(clean_title_en)
                except Exception as e:
                    print(f"ç¿»è¯‘å¤±è´¥: {e}")
                    title_zh = "ç¿»è¯‘æš‚ä¸å¯ç”¨"

                news_items.append({
                    "title_zh": title_zh,
                    "title_en": clean_title_en,
                    "link": link,
                    "date": pub_date
                })
    return news_items

def update_readme(news_items):
    beijing_tz = pytz.timezone('Asia/Shanghai')
    now = datetime.datetime.now(beijing_tz).strftime("%Y-%m-%d %H:%M:%S")
    
    with open("README.md", "r", encoding="utf-8") as f:
        content = f.read()

    header_marker = "## ğŸ§¬ æœ€æ–° CGT è¡Œä¸šåŠ¨æ€"
    
    # æ„å»ºæ–°å†…å®¹å¤´éƒ¨
    if header_marker not in content:
        new_header = content + f"\n\n{header_marker}\n\næ›´æ–°æ—¶é—´: {now}\n\n"
        old_content = ""
    else:
        # ä¿ç•™ Header ä¹‹å‰çš„å†…å®¹ï¼ˆæ¯”å¦‚é¡¹ç›®ä»‹ç»ï¼‰ï¼Œæˆªæ–­æ—§æ–°é—»
        new_header = content.split(header_marker)[0] + f"{header_marker}\n\næ›´æ–°æ—¶é—´: {now}\n\n"
    
    # æ„å»ºæ–°é—»åˆ—è¡¨
    news_list = ""
    for item in news_items:
        # æ ¼å¼ï¼šä¸­æ–‡æ ‡é¢˜ (è‹±æ–‡åŸé¢˜)
        news_list += f"- **{item['title_zh']}** <br> <small>*{item['title_en']}* [é˜…è¯»åŸæ–‡]({item['link']})</small>\n"
    
    if not news_items:
        news_list += "- ä»Šæ—¥æš‚æ— ç¬¦åˆæ¡ä»¶çš„é‡è¦èµ„è®¯ã€‚\n"

    # ç»„åˆæœ€ç»ˆå†…å®¹
    final_content = new_header + news_list

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(final_content)

if __name__ == "__main__":
    items = fetch_news()
    update_readme(items)
